\begin{abstract}

Compilation of programs for distributed memory architectures using message passing is a vital task with potential for speedups over existing techniques. The partitioned global address space (PGAS) parallel programming model exposes locality of reference information to the programmer thereby improving programmability and allowing for compile-time performance optimizations. In particular, programs compiled to message passing hardware can improve in performance by aggregating messages and eliminating dynamic locality checks for affine array accesses in the PGAS model. 

This paper presents a loop optimization for message passing programs that use affine array accesses in Chapel, a PGAS parallel programming language. Each message in Chapel incurs some non-trivial run time overhead. Therefore, aggregating messages improves performance. The optimization is based on a technique known as modulo unrolling where the locality of any affine array access can be deduced at compile time. First pioneered by Barua et al for tiled architectures, we adapt modulo unrolling to the problem of efficiently compiling PGAS languages to message passing architectures. When applied to loops and data distributed cyclically or block cyclically, modulo unrolling can decide when to aggregate messages thereby reducing the overall message count and run time for a particular loop. Compared to other methods, modulo unrolling greatly simplifies the very complex problem of automatic code generation of message passing code from a PGAS language such as Chapel. It also results in substantial performance improvement compared to the unoptimized Chapel compiler.

To implement this optimization in Chapel, we modify the leader and follower iterators in the Cyclic and Block Cyclic data distribution modules. Results were collected that compare the performance of Chapel programs optimized with modulo unrolling with Chapel programs using the existing Chapel data distributions. Data collected for ten parallel benchmarks on a ten-locale cluster show that on average, modulo unrolling used with Chapel's Cyclic distribution results in 69 percent fewer messages and a 30 percent decrease in runtime. Similarly, modulo unrolling used with Chapel's Block Cyclic distribution results in 72 percent fewer messages and a 52 percent decrease in runtime for data collected for two parallel benchmarks. 

\end{abstract}