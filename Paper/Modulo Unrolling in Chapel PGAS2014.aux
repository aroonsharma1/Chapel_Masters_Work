\relax 
\citation{barua1999maps}
\citation{waingold1997baring}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{\thepage }}
\newlabel{sec:intro}{{1}{\thepage }}
\citation{Gupta91automaticdata}
\citation{xue1997communication}
\citation{goumas2006message}
\citation{xue1997communication}
\citation{barua1999maps}
\citation{barua1999maps}
\citation{distributions}
\citation{mace1987memory}
\citation{prylli1997fast}
\citation{walker1996redistribution}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Chapel Block distribution.}}{\thepage }}
\newlabel{block_dist}{{1}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Chapel Cyclic distribution.}}{\thepage }}
\newlabel{cyc_dist}{{2}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {2}Chapel's Data Distributions}{\thepage }}
\newlabel{sec:data_distributions}{{2}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Chapel Block Cyclic distribution with a 2 x 2 block size parameter.}}{\thepage }}
\newlabel{block_cyc_dist}{{3}{\thepage }}
\citation{xue1997communication}
\citation{goumas2006message}
\citation{callahan1988compiling}
\citation{ramanujam1991compile}
\citation{Gupta91automaticdata}
\citation{chavarria2005effective}
\citation{germain1995automatic}
\citation{gupta1996compiling}
\citation{iancu2008performance}
\citation{wei1998compiling}
\citation{sanz2012global}
\citation{sanz2012global}
\citation{sanz2012global}
\citation{sanz2012global}
\citation{sanz2012global}
\citation{sanz2012global}
\citation{chen2005communication}
\citation{chen2005communication}
\citation{barik2011communication}
\citation{barua1999maps}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related Work}{\thepage }}
\newlabel{sec:relwork}{{3}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {4}Background on Modulo Unrolling}{\thepage }}
\newlabel{sec:modulo_unrolling}{{4}{\thepage }}
\citation{barua1999maps}
\citation{barua1999maps}
\@writefile{toc}{\contentsline {section}{\numberline {5}Intuition Behind Message Aggregation With An Example}{\thepage }}
\newlabel{sec:motivation_for_aggregation}{{5}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Modulo unrolling example. (a) Original sequential for loop. Array $A$ is distributed using a Cyclic distribution. Each array access maps to a different memory bank on successive loop iterations. (b) Fully unrolled loop. Trivially, each array access maps to a single memory bank because each access only occurs once. This loop dramatically increases the code size for loops traversing through large data sets. (c) Loop transformed using modulo unrolling. The loop is unrolled by a factor equal to the number of memory banks on the architecture. Now each array access is guaranteed to map to a single memory bank for all loop iterations and code size increases only by the loop unroll factor.}}{\thepage }}
\newlabel{modulo_unrolling}{{4}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Chapel code for the Jacobi-2D computation over an 8 x 8 two dimensional array. Arrays $A$ and $A_{new}$ are distributed with a Cyclic distribution and their declarations are not shown. During each iteration of the loop, the current array element $A_{new}[i, j]$ gets the average of the four adjacent array elements of $A[i, j]$.}}{\thepage }}
\newlabel{jacobi_code}{{5}{\thepage }}
\citation{barua1999maps}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Illustration of message aggregation for the $A[i, j-1]$ affine array access of the Jacobi-2D relaxation computation with respect to locale 3. The region \textit  {LoopSpace} follows from Figure 5\hbox {}. The striped squares are the elements of $A$ that have been aggregated. This same procedure occurs on each locale for each affine array access that is deemed to be remote for all iterations of the loop. For the whole 8 x 8 Jacobi-2D calculation, 144 remote gets containing one element each are necessary without aggregation, but only 16 remote gets containing nine elements each are necessary with aggregation.}}{\thepage }}
\newlabel{aggregation}{{6}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {6}Message Aggregation Loop Optimization for Parallel Affine Loops}{\thepage }}
\newlabel{sec:transformation}{{6}{\thepage }}
\citation{barua1999maps}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Steps to transform a parallel affine loop where the data is distributed cyclically or block-cyclically into an equivalent loop that performs message aggregation. (a) Original distributed parallel loop with two affine array accesses. (b) Loop after Block Cyclic transformation. After this step, the affine array accesses in loops with data distributed block-cyclically will be statically disambiguated. (c) Loop after the owning expression calculation and message aggregation steps. In line 6, remote array elements are communicated to a local buffer before the loop. The affine array access for $A_{2}$ is replaced with an access to the local buffer in line 10. In lines 14-15, elements in the local buffer are written back to the remote locale if they are written to during the loop. (d) Key of symbolic variables used in the transformations in parts a-c. }}{\thepage }}
\newlabel{transformations}{{7}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Modulo Unrolling Without Unrolling}{\thepage }}
\newlabel{subsec:modulo_unrolling_without_unrolling}{{6.1}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Block Cyclic Transformation}{\thepage }}
\newlabel{subsec:block_cyclic_transformation}{{6.2}{\thepage }}
\citation{wu1994static}
\citation{chamberlain2011user}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Owning Expression Calculation}{\thepage }}
\newlabel{subsec:owning_expression_calculation}{{6.3}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Message Aggregation}{\thepage }}
\newlabel{subsec:message_aggregation}{{6.4}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Loops with Multi-Dimensional Array Accesses}{\thepage }}
\newlabel{subsec:multi_dimensional}{{6.5}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {7}Adaptation in Chapel}{\thepage }}
\newlabel{sec:adaptation_in_chapel}{{7}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Chapel Zippered Iteration}{\thepage }}
\newlabel{sec:zippered_iteration}{{7.1}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces (a) Chapel loop written using a single loop induction variable $i$ ranging from 1 to 10. The loop contains two affine array accesses. (b) The same loop written using zippered iterators in Chapel. Instead of a loop induction variable and a range of values to denote the loop bounds, two array slices each containing the 10 elements accessed by the loop in (a) are specified.}}{\thepage }}
\newlabel{affine_loop}{{8}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Chapel Array Slicing}{\thepage }}
\newlabel{sec:array_slicing}{{7.2}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Pseudocode for the Cyclic distribution follower iterator that has been modified to perform modulo unrolling WU. }}{\thepage }}
\newlabel{cyclic_muwu_follower}{{9}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Implementation}{\thepage }}
\newlabel{subsec:cyclic_modulo}{{7.3}{\thepage }}
\citation{polybench}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Benchmark suite. Benchmarks with no symbol after their name were taken from the Polybench suite of benchmarks and translated to Chapel. Benchmarks with $\dagger $ are taken from the Chapel Trunk test directory. Benchmarks with $\ddagger $ were developed on our own in order to test specific data access patterns. We also measure the maximum number of elements per follower iterator chunk of work for each benchmark to get a sense of how much aggregation is possible.}}{\thepage }}
\newlabel{benchmarks}{{10}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {8}Results}{\thepage }}
\newlabel{sec:results}{{8}{\thepage }}
\bibstyle{abbrv}
\bibdata{bibliography.bib}
\bibcite{polybench}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Runtime data collected for our suite of benchmarks. Numbers are normalized to the original Chapel Cyclic and Block Cyclic distributions. }}{\thepage }}
\newlabel{runtimes}{{11}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Message count data collected for our suite of benchmarks. Numbers are normalized to the original Chapel Cyclic and Block Cyclic distributions. }}{\thepage }}
\newlabel{message_counts}{{12}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {9}Future Work}{\thepage }}
\newlabel{sec:future_work}{{9}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {10}References}{\thepage }}
\bibcite{barik2011communication}{2}
\bibcite{barua1999maps}{3}
\bibcite{callahan1988compiling}{4}
\bibcite{chamberlain2011user}{5}
\bibcite{chavarria2005effective}{6}
\bibcite{chen2005communication}{7}
\bibcite{germain1995automatic}{8}
\bibcite{goumas2006message}{9}
\bibcite{Gupta91automaticdata}{10}
\bibcite{gupta1996compiling}{11}
\bibcite{iancu2008performance}{12}
\bibcite{mace1987memory}{13}
\bibcite{prylli1997fast}{14}
\bibcite{ramanujam1991compile}{15}
\bibcite{sanz2012global}{16}
\bibcite{distributions}{17}
\bibcite{waingold1997baring}{18}
\bibcite{walker1996redistribution}{19}
\bibcite{wei1998compiling}{20}
\bibcite{wu1994static}{21}
\bibcite{xue1997communication}{22}
